{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PerceiverIO.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvQ8KOjLdS1W",
        "outputId": "8194e53b-edfe-4042-9f3f-cf57f885f358"
      },
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDyt271-dvMk"
      },
      "source": [
        "# Loading Data Set and Assembling Training, Validation, and Test Sets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S0k8XEaUjb_",
        "outputId": "48055268-705f-4563-c359-5da1bf551063"
      },
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -qq 'tiny-imagenet-200.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-09 16:19:35--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z  42%[=======>            ] 101.45M  17.8MB/s    eta 11s    ^C\n",
            "[tiny-imagenet-200.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of tiny-imagenet-200.zip or\n",
            "        tiny-imagenet-200.zip.zip, and cannot find tiny-imagenet-200.zip.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czvJRFARdrw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a64d141-f9e0-4452-e8f5-68151fa665d0"
      },
      "source": [
        "# Load training dataset, then split into training, validation, and test sets\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torchvision import datasets,transforms\n",
        "import torch.utils.tensorboard as tb\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "dataset = \"CIFAR-10\"\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# create datasets\n",
        "if dataset == \"STL-10\":\n",
        "    training_dataset = datasets.STL10(root='./data/STL10', split='train', transform=transforms.ToTensor(), download=True)\n",
        "    validation_dataset = datasets.STL10(root='./data/STL10', split='test', transform=transforms.ToTensor(), download=True)\n",
        "    in_size = 96\n",
        "    num_classes = 10\n",
        "if dataset == \"CIFAR-10\":\n",
        "    training_dataset = datasets.CIFAR10(root='./data/CIFAR10', train=True, download=True, transform=transforms.ToTensor())\n",
        "    validation_dataset = datasets.CIFAR10(root='./data/CIFAR10', train=False, download=True, transform=transforms.ToTensor())\n",
        "    in_size = 32\n",
        "    num_classes = 10\n",
        "if dataset == \"TinyImageNet\":\n",
        "    training_dataset = datasets.ImageFolder(\"./tiny-imagenet-200/train\", transform=transforms.Compose([transforms.ToTensor()]))\n",
        "    validation_dataset = datasets.ImageFolder(\"./tiny-imagenet-200/val\", transform=transforms.Compose([transforms.ToTensor()]))\n",
        "    in_size = 64\n",
        "    num_classes = 200\n",
        "\n",
        "# create dataloaders\n",
        "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=int(BATCH_SIZE), shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=int(BATCH_SIZE), shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3noKG4aekl9",
        "outputId": "7dbb999c-7564-4637-c83c-3363e7bde94b"
      },
      "source": [
        "!pip install perceiver-pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting perceiver-pytorch\n",
            "  Downloading perceiver_pytorch-0.7.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from perceiver-pytorch) (1.9.0+cu111)\n",
            "Collecting einops>=0.3\n",
            "  Downloading einops-0.3.2-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->perceiver-pytorch) (3.7.4.3)\n",
            "Installing collected packages: einops, perceiver-pytorch\n",
            "Successfully installed einops-0.3.2 perceiver-pytorch-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAZ0PGvWe1Mk",
        "outputId": "7b6ecb5e-20a7-43b8-ad16-5b768d02ef27"
      },
      "source": [
        "import torch\n",
        "from torch import nn, einsum\n",
        "from perceiver_pytorch import PerceiverIO\n",
        "\n",
        "\n",
        "class QueryFFN(nn.Module):\n",
        "    def __init__(self, in_size):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(in_size*in_size, num_classes)\n",
        "      \n",
        "    def forward(self, images):\n",
        "        images = torch.flatten(images, start_dim = 1)\n",
        "        return self.query(images)[:, None, :]\n",
        "\n",
        "\n",
        "original_model = PerceiverIO(\n",
        "    dim = in_size,                    # dimension of sequence to be encoded\n",
        "    queries_dim = num_classes,            # dimension of decoder queries\n",
        "    logits_dim = num_classes,            # dimension of final logits\n",
        "    depth = 5,                   # depth of net\n",
        "    num_latents = 256,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "    latent_dim = 512,            # latent dimension\n",
        "    cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
        "    latent_heads = 8,            # number of heads for latent self attention, 8\n",
        "    cross_dim_head = 64,         # number of dimensions per cross attention head\n",
        "    latent_dim_head = 64,        # number of dimensions per latent self attention head\n",
        "    weight_tie_layers = False,    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        "    decoder_ff = False\n",
        ")\n",
        "\n",
        "seq = torch.randn(3, in_size, in_size)\n",
        "queries = torch.rand(3, 1, num_classes)\n",
        "\n",
        "logits = original_model(seq, queries = queries) # (1, 128, 100) - (batch, decoder seq, logits dim)\n",
        "print(logits.squeeze().size())\n",
        "\n",
        "logits = model(seq)\n",
        "print(logits.size())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 10])\n",
            "torch.Size([3, 1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAKr7zApfFDm"
      },
      "source": [
        "LR = 1e-1\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 1e-6\n",
        "EPOCHS = 8\n",
        "\n",
        "def train_model(model_in, learning_rate = LR, weight_d = WEIGHT_DECAY, momentum = MOMENTUM):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model = model_in\n",
        "  model = model.to(device)\n",
        "  query_model = QueryFFN(in_size)\n",
        "  query_model = query_model.to(device)\n",
        "\n",
        "  # Define Loss Function and get optimizer\n",
        "  train_loss = {}\n",
        "  validation_acc = {}\n",
        "  loss_f = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = LR, weight_decay=WEIGHT_DECAY, betas=(momentum, 0.999))\n",
        "  query_optimizer = torch.optim.Adam(query_model.parameters(), lr = 1e-2, weight_decay = WEIGHT_DECAY)\n",
        "  epoch_loss = {}\n",
        "  for epoch in range (EPOCHS):\n",
        "    print(\"EPOCH : \", epoch)\n",
        "    model.train()\n",
        "    query_model.train()\n",
        "    batch_loss = []\n",
        "    \n",
        "    accuracies = []\n",
        "    num = 0\n",
        "    # Iterate through training set, collect loss values and update model\n",
        "    for im, truth_labels in training_loader:\n",
        "      num += 1\n",
        "      if num > 500:\n",
        "        break\n",
        "\n",
        "      im = im.mean(1)\n",
        "      # print(im.size())\n",
        "      im = im.to(device)\n",
        "      queries = query_model(im)\n",
        "      queries = queries.to(device)\n",
        "      truth_labels = truth_labels.to(device)\n",
        "      predicted_labels = model(im, queries = queries).squeeze()\n",
        "      predicted_labels = predicted_labels.to(device)\n",
        "      loss = loss_f(predicted_labels, truth_labels)\n",
        "      print(loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      query_optimizer.step()\n",
        "      query_optimizer.zero_grad()\n",
        "      batch_loss.append(loss.item())\n",
        "      accuracy = (predicted_labels.argmax(1) == truth_labels).float().mean().item()\n",
        "      accuracies.append(accuracy)\n",
        "\n",
        "    print(\"******Train ACCURACY****** : \", torch.FloatTensor(accuracies).mean().item())\n",
        "    print(\"TRAIN_LOSS of Each Batch: \", torch.FloatTensor(batch_loss).mean().item())\n",
        "    epoch_loss[epoch] = batch_loss\n",
        "\n",
        "    # Iterate through validation set and compute validation accuracy\n",
        "    model.eval()\n",
        "    query_model.eval()\n",
        "    accuracies = []\n",
        "    for validation_im, validation_labels in validation_loader:\n",
        "      validation_im = validation_im.to(device)\n",
        "      validation_im = validation_im.mean(1)\n",
        "      validation_labels = validation_labels.to(device)\n",
        "      queries = query_model(validation_im)\n",
        "      queries = queries.to(device)\n",
        "      predicted_labels = model(validation_im, queries = queries).squeeze().argmax(1)\n",
        "      accuracy = (predicted_labels == validation_labels).float().mean().item()\n",
        "      accuracies.append(accuracy)\n",
        "    \n",
        "    validation_set_accuracy = torch.FloatTensor(accuracies).mean().item()\n",
        "    print(\"******VALIDATION ACCURACY****** : \", validation_set_accuracy)\n",
        "    validation_acc[epoch] = validation_set_accuracy\n",
        "\n",
        "  # # Calculate test set accuracy\n",
        "  # model.eval()\n",
        "  # accuracies = []\n",
        "  # for test_im, test_labels in test_set:\n",
        "  #     test_im = test_im.to(device)\n",
        "  #     test_labels = test_labels.to(device)\n",
        "\n",
        "  #     predicted_labels = model(test_im).argmax(1)\n",
        "  #     accuracy = (predicted_labels == test_labels).float().mean().item()\n",
        "  #     accuracies.append(accuracy)\n",
        "    \n",
        "  # test_set_accuracy = torch.FloatTensor(accuracies).mean().item()\n",
        "  # print(\"******TEST ACCURACY****** : \", test_set_accuracy)\n",
        "  # return train_loss, validation_acc, test_set_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zrsEVLK3g7Kq",
        "outputId": "362a9682-057a-4537-bcc2-e2b0bad95752"
      },
      "source": [
        "train_model(original_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH :  0\n",
            "tensor(2.2611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(6.2336, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(85.2318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(163.6691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(118.8763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(63.4948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(41.1605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(260.7211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(55.8646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(144.7871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(180.2741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(105.3125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(49.1882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(71.1342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(96.3773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(193.8064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(122.4519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(48.2441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(122.0403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(86.1072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(44.2057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(49.7293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(51.2065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(54.3113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(32.3196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(24.0898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(44.5847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(18.7337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(36.2814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(40.0712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(53.2159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(30.3326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(27.0851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(12.4009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(34.4894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(12.0536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(25.3570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(25.4279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(14.6338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(8.1893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(9.2892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(15.4451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(20.4659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(11.9052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(9.0208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(6.4785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(4.0655, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(6.9644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(5.2349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(7.6888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(7.9798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(8.1359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(3.4300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(6.9557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(9.4008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(7.0307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(5.7688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(5.9431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(6.2647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(5.2508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(5.1239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(6.4133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(5.7365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(6.3932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(4.0370, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(3.8555, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(5.2914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(4.2035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.9542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(3.2008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(3.0061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.9663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.6444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.6535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.7552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(3.0600, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.6229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.7885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.7401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.7363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.7087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5448, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2790, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.9952, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.6328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5000, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.7898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.7620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.6259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.8985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.7549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3495, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.7309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.6095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3510, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1439, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4360, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3417, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5754, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5420, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3600, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.6566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(1.9900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4195, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3420, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3299, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3069, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4201, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.0291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.6929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4432, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4245, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3105, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3589, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2142, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3142, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.6830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3141, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3168, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1210, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4141, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3037, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.5303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4457, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4367, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "******Train ACCURACY****** :  0.109375\n",
            "TRAIN_LOSS of Each Batch:  7.778621196746826\n",
            "******VALIDATION ACCURACY****** :  0.1256999969482422\n",
            "EPOCH :  1\n",
            "tensor(2.4924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3655, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3100, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3097, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2464, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.1630, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3105, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2091, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2289, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.3269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.4806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "tensor(2.2660, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-4d29804edb82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-b21422c45651>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_in, learning_rate, weight_d, momentum)\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m       \u001b[0mquery_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mquery_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    214\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KCEjSk5FeLH"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}