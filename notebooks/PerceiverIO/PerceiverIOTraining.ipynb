{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PerceiverIOTraining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H5dpVdYTdEV",
        "outputId": "db06b0d1-07bc-43f5-c9b5-dcf48ae928d7"
      },
      "source": [
        "!pip install ml_collections\n",
        "!pip install perceiver-pytorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ml_collections\n",
            "  Downloading ml_collections-0.1.0-py3-none-any.whl (88 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 40 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 51 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 61 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 71 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 81 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 88 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml_collections) (0.5.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ml_collections) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from ml_collections) (3.13)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from ml_collections) (0.12.0)\n",
            "Installing collected packages: ml-collections\n",
            "Successfully installed ml-collections-0.1.0\n",
            "Collecting perceiver-pytorch\n",
            "  Downloading perceiver_pytorch-0.7.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from perceiver-pytorch) (1.9.0+cu111)\n",
            "Collecting einops>=0.3\n",
            "  Downloading einops-0.3.2-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->perceiver-pytorch) (3.7.4.3)\n",
            "Installing collected packages: einops, perceiver-pytorch\n",
            "Successfully installed einops-0.3.2 perceiver-pytorch-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrZkkxXN-zl_",
        "outputId": "acc37e20-d95c-487f-aae4-230618238851"
      },
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -qq 'tiny-imagenet-200.zip'"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-10 06:54:30--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  6.72MB/s    in 40s     \n",
            "\n",
            "2021-10-10 06:55:10 (5.96 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCdIcgZCUoP9"
      },
      "source": [
        "from ml_collections import ConfigDict\n",
        "\n",
        "def C(**kwargs):\n",
        "    return ConfigDict(initial_dictionary=kwargs)\n",
        "\n",
        "def get_config():\n",
        "    return C(\n",
        "        cuda                = True,\n",
        "        dataset             = 'cifar10',\n",
        "        image_size          = 32,\n",
        "        num_classes         = 10,\n",
        "\n",
        "        train=C(\n",
        "            batch_size          = 128,\n",
        "            num_epochs          = 100,\n",
        "        ),\n",
        "\n",
        "        optimizer_type      = 'adamw',\n",
        "        optimizer_args=C(\n",
        "            lr                  = 3e-4,\n",
        "        ),\n",
        "\n",
        "        model_type          = 'perceiver_io',\n",
        "        model_args=C(\n",
        "            dim = 32 * 32 * 3,                    # dimension of sequence to be encoded\n",
        "            queries_dim = 10,            # dimension of decoder queries\n",
        "            logits_dim = 10,            # dimension of final logits\n",
        "            depth = 2,                   # depth of net\n",
        "            num_latents = 32,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "            latent_dim = 64,            # latent dimension\n",
        "            cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
        "            latent_heads = 8,            # number of heads for latent self attention, 8\n",
        "            cross_dim_head = 128,         # number of dimensions per cross attention head\n",
        "            latent_dim_head = 128,        # number of dimensions per latent self attention head\n",
        "            weight_tie_layers = False,    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        "            decoder_ff = False\n",
        "        ),\n",
        "    )"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHQmFh8kV1ZF"
      },
      "source": [
        "def load_config(config_name):\n",
        "    return {\n",
        "        'perceiver_io': get_config(),\n",
        "    }[config_name]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZzGzj3kWGFi"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from perceiver_pytorch import Perceiver, PerceiverIO\n",
        "\n",
        "def get_datasets(dataset, data_root):\n",
        "    assert dataset in ('stl10', 'cifar10', 'tinyimagenet')\n",
        "    data_root = os.path.abspath(os.path.expanduser(data_root))\n",
        "    root_dir = os.path.join(data_root, dataset)\n",
        "    transform_train = transforms.Compose([\n",
        "      transforms.RandomHorizontalFlip(p = 0.5),\n",
        "      transforms.ColorJitter(brightness=0.5, hue = 0.25),\n",
        "      transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    if dataset == 'stl10':\n",
        "        train_dataset = datasets.STL10(root=root_dir, split='train', transform=transforms.ToTensor(), download=True)\n",
        "        test_dataset = datasets.STL10(root=root_dir, split='test', transform=transforms.ToTensor(), download=True)\n",
        "    elif dataset == 'cifar10':\n",
        "        train_dataset = datasets.CIFAR10(root=root_dir, train=True, download=True, transform=transform_train)\n",
        "        test_dataset = datasets.CIFAR10(root=root_dir, train=False, download=True, transform=transform_test)\n",
        "    elif dataset == 'tinyimagenet':\n",
        "        train_dataset = datasets.ImageFolder(\"./tiny-imagenet-200/train\", transform=transform_train)\n",
        "        test_dataset = datasets.ImageFolder(\"./tiny-imagenet-200/val\", transform=transform_test)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "def get_model(config):\n",
        "    model_cls = {'perceiver': Perceiver,\n",
        "                 'perceiver_io': PerceiverIO\n",
        "                 }[config.model_type]\n",
        "    model = model_cls(**config.model_args)\n",
        "    param_count = sum(np.prod(p.shape).item() for p in model.parameters())\n",
        "    print(f'Created {config.model_type} model with {param_count} parameters.')\n",
        "    if config.cuda:\n",
        "        model.cuda()\n",
        "    temp = torch.nn.Parameter(torch.rand(config.train['batch_size'], 32, config['num_classes']), requires_grad = True)\n",
        "    model.register_parameter(name='query_io', param=temp)\n",
        "    return model\n",
        "\n",
        "def get_optimizer(model, config):\n",
        "    optimizer_cls = {'adamw': optim.AdamW,\n",
        "                     'rmsprop': optim.RMSprop\n",
        "                     }[config.optimizer_type]\n",
        "    optimizer = optimizer_cls(model.parameters(), **config.optimizer_args)\n",
        "    return optimizer\n",
        "\n",
        "def train(config):\n",
        "    train_dataset, test_dataset = get_datasets(config.dataset, 'data')\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.train.batch_size,\n",
        "                                               shuffle=True, pin_memory=config.cuda, drop_last=False)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config.train.batch_size,\n",
        "                                              shuffle=False, pin_memory=config.cuda, drop_last=False)\n",
        "    model = get_model(config)\n",
        "    opt = get_optimizer(model, config)\n",
        "\n",
        "    total_steps = 0\n",
        "    for epoch in range(1, config.train.num_epochs+1):\n",
        "        print(f'Starting epoch {epoch}')\n",
        "\n",
        "        for _, (x, y) in enumerate(train_loader):\n",
        "            total_steps += 1\n",
        "            if len(x) != 128:\n",
        "              break\n",
        "            if config.cuda:\n",
        "                x, y = x.cuda(), y.cuda()\n",
        "            x = x.permute(0, 2, 3, 1) * 2 - 1\n",
        "            x = torch.flatten(x, start_dim = 1, end_dim = 3)\n",
        "            queries = model.query_io.data\n",
        "            queries = queries.cuda()\n",
        "            y_hat = model(x[:, None, :], queries = queries).mean(1).squeeze()\n",
        "            opt.zero_grad()\n",
        "            loss = F.cross_entropy(y_hat, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            if total_steps % 100 == 0:\n",
        "                print(f'epoch {epoch} step {total_steps} loss {loss.item():.4f}')\n",
        "        print(f'epoch {epoch} step {total_steps} loss {loss.item():.4f}')\n",
        "\n",
        "        ep_train_loss, ep_train_acc = evaluate(model, train_dataset, config)\n",
        "        print(f'epoch {epoch} Train accuracy: {ep_train_acc:.4f} loss: {ep_train_loss:.4f}')\n",
        "        ep_test_loss, ep_test_acc = evaluate(model, test_dataset, config)\n",
        "        print(f'epoch {epoch} Test accuracy: {ep_test_acc:.4f} loss: {ep_test_loss:.4f}')\n",
        "        print()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, dataset, config):\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=config.train.batch_size,\n",
        "                                              shuffle=False, pin_memory=config.cuda,\n",
        "                                              drop_last=False)\n",
        "    model.eval()\n",
        "    losses, preds = [], []\n",
        "    for x, y in data_loader:\n",
        "        if len(x) != 128:\n",
        "            break\n",
        "        if config.cuda:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "        x = x.permute(0, 2, 3, 1) * 2 - 1\n",
        "        x = torch.flatten(x, start_dim = 1, end_dim = 3)\n",
        "        queries = model.query_io.data\n",
        "        queries = queries.cuda()\n",
        "        y_hat = model(x[:, None, :], queries = queries).mean(1).squeeze()\n",
        "        y_pred = y_hat.argmax(axis=-1)\n",
        "        loss = F.cross_entropy(y_hat, y, reduction='none')\n",
        "        pred = (y_pred == y).long()\n",
        "        losses.append(loss)\n",
        "        preds.append(pred)\n",
        "\n",
        "    avg_loss = torch.cat(losses).cpu().mean().item()\n",
        "    accuracy = torch.cat(preds).cpu().float().mean().item()\n",
        "\n",
        "    return avg_loss, accuracy\n"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FihT_xKKW2WN",
        "outputId": "f6f74fed-2c81-48f8-8226-06ace1dfcce1"
      },
      "source": [
        "config = load_config('perceiver_io')\n",
        "train(config)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Created perceiver_io model with 1504652 parameters.\n",
            "Starting epoch 1\n",
            "epoch 1 step 100 loss 1.9702\n",
            "epoch 1 step 200 loss 1.9486\n",
            "epoch 1 step 300 loss 1.8389\n",
            "epoch 1 step 391 loss 1.8121\n",
            "epoch 1 Train accuracy: 0.3877 loss: 1.7115\n",
            "epoch 1 Test accuracy: 0.4094 loss: 1.6638\n",
            "\n",
            "Starting epoch 2\n",
            "epoch 2 step 400 loss 1.5476\n",
            "epoch 2 step 500 loss 1.8173\n",
            "epoch 2 step 600 loss 1.5951\n",
            "epoch 2 step 700 loss 1.5754\n",
            "epoch 2 step 782 loss 1.5566\n",
            "epoch 2 Train accuracy: 0.4348 loss: 1.5992\n",
            "epoch 2 Test accuracy: 0.4426 loss: 1.5640\n",
            "\n",
            "Starting epoch 3\n",
            "epoch 3 step 800 loss 1.6381\n",
            "epoch 3 step 900 loss 1.5764\n",
            "epoch 3 step 1000 loss 1.5905\n",
            "epoch 3 step 1100 loss 1.4677\n",
            "epoch 3 step 1173 loss 1.8356\n",
            "epoch 3 Train accuracy: 0.4592 loss: 1.5191\n",
            "epoch 3 Test accuracy: 0.4677 loss: 1.5011\n",
            "\n",
            "Starting epoch 4\n",
            "epoch 4 step 1200 loss 1.5768\n",
            "epoch 4 step 1300 loss 1.4858\n",
            "epoch 4 step 1400 loss 1.4332\n",
            "epoch 4 step 1500 loss 1.5959\n",
            "epoch 4 step 1564 loss 1.5184\n",
            "epoch 4 Train accuracy: 0.4773 loss: 1.4709\n",
            "epoch 4 Test accuracy: 0.4778 loss: 1.4682\n",
            "\n",
            "Starting epoch 5\n",
            "epoch 5 step 1600 loss 1.5441\n",
            "epoch 5 step 1700 loss 1.4507\n",
            "epoch 5 step 1800 loss 1.2289\n",
            "epoch 5 step 1900 loss 1.3139\n",
            "epoch 5 step 1955 loss 1.5113\n",
            "epoch 5 Train accuracy: 0.4929 loss: 1.4262\n",
            "epoch 5 Test accuracy: 0.4949 loss: 1.4314\n",
            "\n",
            "Starting epoch 6\n",
            "epoch 6 step 2000 loss 1.3519\n",
            "epoch 6 step 2100 loss 1.4855\n",
            "epoch 6 step 2200 loss 1.3471\n",
            "epoch 6 step 2300 loss 1.3193\n",
            "epoch 6 step 2346 loss 1.2436\n",
            "epoch 6 Train accuracy: 0.5153 loss: 1.3755\n",
            "epoch 6 Test accuracy: 0.5028 loss: 1.3999\n",
            "\n",
            "Starting epoch 7\n",
            "epoch 7 step 2400 loss 1.3680\n",
            "epoch 7 step 2500 loss 1.5283\n",
            "epoch 7 step 2600 loss 1.4233\n",
            "epoch 7 step 2700 loss 1.4298\n",
            "epoch 7 step 2737 loss 1.3623\n",
            "epoch 7 Train accuracy: 0.5231 loss: 1.3516\n",
            "epoch 7 Test accuracy: 0.5111 loss: 1.3842\n",
            "\n",
            "Starting epoch 8\n",
            "epoch 8 step 2800 loss 1.4252\n",
            "epoch 8 step 2900 loss 1.3773\n",
            "epoch 8 step 3000 loss 1.1364\n",
            "epoch 8 step 3100 loss 1.3897\n",
            "epoch 8 step 3128 loss 1.3226\n",
            "epoch 8 Train accuracy: 0.5321 loss: 1.3192\n",
            "epoch 8 Test accuracy: 0.5162 loss: 1.3642\n",
            "\n",
            "Starting epoch 9\n",
            "epoch 9 step 3200 loss 1.2793\n",
            "epoch 9 step 3300 loss 1.2788\n",
            "epoch 9 step 3400 loss 1.2652\n",
            "epoch 9 step 3500 loss 1.4205\n",
            "epoch 9 step 3519 loss 1.3329\n",
            "epoch 9 Train accuracy: 0.5386 loss: 1.2970\n",
            "epoch 9 Test accuracy: 0.5155 loss: 1.3630\n",
            "\n",
            "Starting epoch 10\n",
            "epoch 10 step 3600 loss 1.2530\n",
            "epoch 10 step 3700 loss 1.3667\n",
            "epoch 10 step 3800 loss 1.2926\n",
            "epoch 10 step 3900 loss 1.2036\n",
            "epoch 10 step 3910 loss 1.2929\n",
            "epoch 10 Train accuracy: 0.5508 loss: 1.2672\n",
            "epoch 10 Test accuracy: 0.5219 loss: 1.3481\n",
            "\n",
            "Starting epoch 11\n",
            "epoch 11 step 4000 loss 1.3797\n",
            "epoch 11 step 4100 loss 1.0939\n",
            "epoch 11 step 4200 loss 1.2601\n",
            "epoch 11 step 4300 loss 1.2744\n",
            "epoch 11 step 4301 loss 1.2744\n",
            "epoch 11 Train accuracy: 0.5552 loss: 1.2509\n",
            "epoch 11 Test accuracy: 0.5210 loss: 1.3499\n",
            "\n",
            "Starting epoch 12\n",
            "epoch 12 step 4400 loss 1.4076\n",
            "epoch 12 step 4500 loss 1.2863\n",
            "epoch 12 step 4600 loss 1.3640\n",
            "epoch 12 step 4692 loss 1.2177\n",
            "epoch 12 Train accuracy: 0.5676 loss: 1.2244\n",
            "epoch 12 Test accuracy: 0.5303 loss: 1.3355\n",
            "\n",
            "Starting epoch 13\n",
            "epoch 13 step 4700 loss 1.3107\n",
            "epoch 13 step 4800 loss 1.3236\n",
            "epoch 13 step 4900 loss 1.2615\n",
            "epoch 13 step 5000 loss 1.2645\n",
            "epoch 13 step 5083 loss 1.3255\n",
            "epoch 13 Train accuracy: 0.5717 loss: 1.2085\n",
            "epoch 13 Test accuracy: 0.5322 loss: 1.3341\n",
            "\n",
            "Starting epoch 14\n",
            "epoch 14 step 5100 loss 1.1879\n",
            "epoch 14 step 5200 loss 1.2702\n",
            "epoch 14 step 5300 loss 1.1358\n",
            "epoch 14 step 5400 loss 1.2770\n",
            "epoch 14 step 5474 loss 1.1425\n",
            "epoch 14 Train accuracy: 0.5797 loss: 1.1880\n",
            "epoch 14 Test accuracy: 0.5387 loss: 1.3285\n",
            "\n",
            "Starting epoch 15\n",
            "epoch 15 step 5500 loss 1.1396\n",
            "epoch 15 step 5600 loss 1.1784\n",
            "epoch 15 step 5700 loss 1.0594\n",
            "epoch 15 step 5800 loss 1.2686\n",
            "epoch 15 step 5865 loss 1.0297\n",
            "epoch 15 Train accuracy: 0.5848 loss: 1.1749\n",
            "epoch 15 Test accuracy: 0.5338 loss: 1.3359\n",
            "\n",
            "Starting epoch 16\n",
            "epoch 16 step 5900 loss 1.0664\n",
            "epoch 16 step 6000 loss 1.2182\n",
            "epoch 16 step 6100 loss 1.0404\n",
            "epoch 16 step 6200 loss 1.2988\n",
            "epoch 16 step 6256 loss 1.1577\n",
            "epoch 16 Train accuracy: 0.5942 loss: 1.1502\n",
            "epoch 16 Test accuracy: 0.5339 loss: 1.3285\n",
            "\n",
            "Starting epoch 17\n",
            "epoch 17 step 6300 loss 1.1084\n",
            "epoch 17 step 6400 loss 1.1688\n",
            "epoch 17 step 6500 loss 1.1259\n",
            "epoch 17 step 6600 loss 1.1952\n",
            "epoch 17 step 6647 loss 1.1128\n",
            "epoch 17 Train accuracy: 0.5995 loss: 1.1287\n",
            "epoch 17 Test accuracy: 0.5352 loss: 1.3257\n",
            "\n",
            "Starting epoch 18\n",
            "epoch 18 step 6700 loss 1.2307\n",
            "epoch 18 step 6800 loss 1.2267\n",
            "epoch 18 step 6900 loss 1.2676\n",
            "epoch 18 step 7000 loss 1.0389\n",
            "epoch 18 step 7038 loss 1.0744\n",
            "epoch 18 Train accuracy: 0.6063 loss: 1.1116\n",
            "epoch 18 Test accuracy: 0.5388 loss: 1.3241\n",
            "\n",
            "Starting epoch 19\n",
            "epoch 19 step 7100 loss 1.0190\n",
            "epoch 19 step 7200 loss 1.2243\n",
            "epoch 19 step 7300 loss 1.0282\n",
            "epoch 19 step 7400 loss 1.2462\n",
            "epoch 19 step 7429 loss 1.1790\n",
            "epoch 19 Train accuracy: 0.6104 loss: 1.1009\n",
            "epoch 19 Test accuracy: 0.5394 loss: 1.3309\n",
            "\n",
            "Starting epoch 20\n",
            "epoch 20 step 7500 loss 1.1388\n",
            "epoch 20 step 7600 loss 1.1120\n",
            "epoch 20 step 7700 loss 1.2236\n",
            "epoch 20 step 7800 loss 0.9510\n",
            "epoch 20 step 7820 loss 0.9931\n",
            "epoch 20 Train accuracy: 0.6208 loss: 1.0756\n",
            "epoch 20 Test accuracy: 0.5389 loss: 1.3294\n",
            "\n",
            "Starting epoch 21\n",
            "epoch 21 step 7900 loss 1.1477\n",
            "epoch 21 step 8000 loss 0.9828\n",
            "epoch 21 step 8100 loss 1.2298\n",
            "epoch 21 step 8200 loss 1.1108\n",
            "epoch 21 step 8211 loss 1.1144\n",
            "epoch 21 Train accuracy: 0.6260 loss: 1.0568\n",
            "epoch 21 Test accuracy: 0.5399 loss: 1.3261\n",
            "\n",
            "Starting epoch 22\n",
            "epoch 22 step 8300 loss 1.1746\n",
            "epoch 22 step 8400 loss 1.1643\n",
            "epoch 22 step 8500 loss 1.1845\n",
            "epoch 22 step 8600 loss 0.9308\n",
            "epoch 22 step 8602 loss 1.1682\n",
            "epoch 22 Train accuracy: 0.6285 loss: 1.0503\n",
            "epoch 22 Test accuracy: 0.5371 loss: 1.3444\n",
            "\n",
            "Starting epoch 23\n",
            "epoch 23 step 8700 loss 1.0956\n",
            "epoch 23 step 8800 loss 1.1064\n",
            "epoch 23 step 8900 loss 1.0050\n",
            "epoch 23 step 8993 loss 1.0381\n",
            "epoch 23 Train accuracy: 0.6394 loss: 1.0214\n",
            "epoch 23 Test accuracy: 0.5419 loss: 1.3324\n",
            "\n",
            "Starting epoch 24\n",
            "epoch 24 step 9000 loss 1.0184\n",
            "epoch 24 step 9100 loss 1.2028\n",
            "epoch 24 step 9200 loss 1.1008\n",
            "epoch 24 step 9300 loss 1.0357\n",
            "epoch 24 step 9384 loss 1.1047\n",
            "epoch 24 Train accuracy: 0.6448 loss: 1.0031\n",
            "epoch 24 Test accuracy: 0.5366 loss: 1.3455\n",
            "\n",
            "Starting epoch 25\n",
            "epoch 25 step 9400 loss 1.1617\n",
            "epoch 25 step 9500 loss 1.0292\n",
            "epoch 25 step 9600 loss 0.9157\n",
            "epoch 25 step 9700 loss 0.9023\n",
            "epoch 25 step 9775 loss 1.1365\n",
            "epoch 25 Train accuracy: 0.6528 loss: 0.9883\n",
            "epoch 25 Test accuracy: 0.5416 loss: 1.3342\n",
            "\n",
            "Starting epoch 26\n",
            "epoch 26 step 9800 loss 0.8310\n",
            "epoch 26 step 9900 loss 0.9738\n",
            "epoch 26 step 10000 loss 1.1374\n",
            "epoch 26 step 10100 loss 1.1016\n",
            "epoch 26 step 10166 loss 1.1087\n",
            "epoch 26 Train accuracy: 0.6509 loss: 0.9818\n",
            "epoch 26 Test accuracy: 0.5445 loss: 1.3451\n",
            "\n",
            "Starting epoch 27\n",
            "epoch 27 step 10200 loss 0.9262\n",
            "epoch 27 step 10300 loss 0.9944\n",
            "epoch 27 step 10400 loss 0.9768\n",
            "epoch 27 step 10500 loss 0.8871\n",
            "epoch 27 step 10557 loss 0.9852\n",
            "epoch 27 Train accuracy: 0.6582 loss: 0.9658\n",
            "epoch 27 Test accuracy: 0.5466 loss: 1.3416\n",
            "\n",
            "Starting epoch 28\n",
            "epoch 28 step 10600 loss 0.9414\n",
            "epoch 28 step 10700 loss 0.9459\n",
            "epoch 28 step 10800 loss 0.9491\n",
            "epoch 28 step 10900 loss 1.2783\n",
            "epoch 28 step 10948 loss 0.9479\n",
            "epoch 28 Train accuracy: 0.6619 loss: 0.9586\n",
            "epoch 28 Test accuracy: 0.5361 loss: 1.3816\n",
            "\n",
            "Starting epoch 29\n",
            "epoch 29 step 11000 loss 0.9623\n",
            "epoch 29 step 11100 loss 0.9976\n",
            "epoch 29 step 11200 loss 1.1227\n",
            "epoch 29 step 11300 loss 0.9874\n",
            "epoch 29 step 11339 loss 0.9059\n",
            "epoch 29 Train accuracy: 0.6678 loss: 0.9348\n",
            "epoch 29 Test accuracy: 0.5358 loss: 1.3932\n",
            "\n",
            "Starting epoch 30\n",
            "epoch 30 step 11400 loss 1.0420\n",
            "epoch 30 step 11500 loss 1.0180\n",
            "epoch 30 step 11600 loss 0.8397\n",
            "epoch 30 step 11700 loss 0.9341\n",
            "epoch 30 step 11730 loss 1.2081\n",
            "epoch 30 Train accuracy: 0.6754 loss: 0.9166\n",
            "epoch 30 Test accuracy: 0.5436 loss: 1.3830\n",
            "\n",
            "Starting epoch 31\n",
            "epoch 31 step 11800 loss 0.9034\n",
            "epoch 31 step 11900 loss 0.8965\n",
            "epoch 31 step 12000 loss 1.0582\n",
            "epoch 31 step 12100 loss 0.8593\n",
            "epoch 31 step 12121 loss 0.7996\n",
            "epoch 31 Train accuracy: 0.6819 loss: 0.9024\n",
            "epoch 31 Test accuracy: 0.5410 loss: 1.3926\n",
            "\n",
            "Starting epoch 32\n",
            "epoch 32 step 12200 loss 0.9006\n",
            "epoch 32 step 12300 loss 0.9955\n",
            "epoch 32 step 12400 loss 1.0718\n",
            "epoch 32 step 12500 loss 0.9206\n",
            "epoch 32 step 12512 loss 1.0107\n",
            "epoch 32 Train accuracy: 0.6893 loss: 0.8809\n",
            "epoch 32 Test accuracy: 0.5390 loss: 1.3957\n",
            "\n",
            "Starting epoch 33\n",
            "epoch 33 step 12600 loss 0.8849\n",
            "epoch 33 step 12700 loss 1.1810\n",
            "epoch 33 step 12800 loss 0.9097\n",
            "epoch 33 step 12900 loss 0.8758\n",
            "epoch 33 step 12903 loss 0.9120\n",
            "epoch 33 Train accuracy: 0.6870 loss: 0.8819\n",
            "epoch 33 Test accuracy: 0.5384 loss: 1.4122\n",
            "\n",
            "Starting epoch 34\n",
            "epoch 34 step 13000 loss 0.9531\n",
            "epoch 34 step 13100 loss 0.8260\n",
            "epoch 34 step 13200 loss 0.9913\n",
            "epoch 34 step 13294 loss 0.9883\n",
            "epoch 34 Train accuracy: 0.6968 loss: 0.8590\n",
            "epoch 34 Test accuracy: 0.5350 loss: 1.4175\n",
            "\n",
            "Starting epoch 35\n",
            "epoch 35 step 13300 loss 0.9054\n",
            "epoch 35 step 13400 loss 0.9780\n",
            "epoch 35 step 13500 loss 0.9136\n",
            "epoch 35 step 13600 loss 0.8459\n",
            "epoch 35 step 13685 loss 0.7625\n",
            "epoch 35 Train accuracy: 0.6989 loss: 0.8475\n",
            "epoch 35 Test accuracy: 0.5357 loss: 1.4400\n",
            "\n",
            "Starting epoch 36\n",
            "epoch 36 step 13700 loss 0.7986\n",
            "epoch 36 step 13800 loss 0.8446\n",
            "epoch 36 step 13900 loss 0.8573\n",
            "epoch 36 step 14000 loss 0.8802\n",
            "epoch 36 step 14076 loss 0.9219\n",
            "epoch 36 Train accuracy: 0.7036 loss: 0.8360\n",
            "epoch 36 Test accuracy: 0.5371 loss: 1.4418\n",
            "\n",
            "Starting epoch 37\n",
            "epoch 37 step 14100 loss 0.8104\n",
            "epoch 37 step 14200 loss 0.8687\n",
            "epoch 37 step 14300 loss 0.9470\n",
            "epoch 37 step 14400 loss 0.8213\n",
            "epoch 37 step 14467 loss 0.8006\n",
            "epoch 37 Train accuracy: 0.7090 loss: 0.8162\n",
            "epoch 37 Test accuracy: 0.5349 loss: 1.4600\n",
            "\n",
            "Starting epoch 38\n",
            "epoch 38 step 14500 loss 0.7617\n",
            "epoch 38 step 14600 loss 0.7922\n",
            "epoch 38 step 14700 loss 0.8783\n",
            "epoch 38 step 14800 loss 0.9879\n",
            "epoch 38 step 14858 loss 0.8677\n",
            "epoch 38 Train accuracy: 0.7182 loss: 0.8004\n",
            "epoch 38 Test accuracy: 0.5283 loss: 1.4735\n",
            "\n",
            "Starting epoch 39\n",
            "epoch 39 step 14900 loss 0.9078\n",
            "epoch 39 step 15000 loss 0.9477\n",
            "epoch 39 step 15100 loss 0.7794\n",
            "epoch 39 step 15200 loss 0.7000\n",
            "epoch 39 step 15249 loss 1.1202\n",
            "epoch 39 Train accuracy: 0.7203 loss: 0.7914\n",
            "epoch 39 Test accuracy: 0.5301 loss: 1.4881\n",
            "\n",
            "Starting epoch 40\n",
            "epoch 40 step 15300 loss 0.8830\n",
            "epoch 40 step 15400 loss 0.8608\n",
            "epoch 40 step 15500 loss 0.8616\n",
            "epoch 40 step 15600 loss 0.8534\n",
            "epoch 40 step 15640 loss 0.6794\n",
            "epoch 40 Train accuracy: 0.7298 loss: 0.7655\n",
            "epoch 40 Test accuracy: 0.5352 loss: 1.4888\n",
            "\n",
            "Starting epoch 41\n",
            "epoch 41 step 15700 loss 0.6544\n",
            "epoch 41 step 15800 loss 0.9309\n",
            "epoch 41 step 15900 loss 0.8483\n",
            "epoch 41 step 16000 loss 0.5481\n",
            "epoch 41 step 16031 loss 0.8375\n",
            "epoch 41 Train accuracy: 0.7366 loss: 0.7437\n",
            "epoch 41 Test accuracy: 0.5349 loss: 1.4962\n",
            "\n",
            "Starting epoch 42\n",
            "epoch 42 step 16100 loss 0.7025\n",
            "epoch 42 step 16200 loss 0.8160\n",
            "epoch 42 step 16300 loss 0.9434\n",
            "epoch 42 step 16400 loss 0.7668\n",
            "epoch 42 step 16422 loss 0.9957\n",
            "epoch 42 Train accuracy: 0.7388 loss: 0.7410\n",
            "epoch 42 Test accuracy: 0.5307 loss: 1.5284\n",
            "\n",
            "Starting epoch 43\n",
            "epoch 43 step 16500 loss 0.6754\n",
            "epoch 43 step 16600 loss 0.7495\n",
            "epoch 43 step 16700 loss 0.9340\n",
            "epoch 43 step 16800 loss 0.6986\n",
            "epoch 43 step 16813 loss 0.7695\n",
            "epoch 43 Train accuracy: 0.7422 loss: 0.7301\n",
            "epoch 43 Test accuracy: 0.5332 loss: 1.5415\n",
            "\n",
            "Starting epoch 44\n",
            "epoch 44 step 16900 loss 0.7946\n",
            "epoch 44 step 17000 loss 0.7982\n",
            "epoch 44 step 17100 loss 0.6946\n",
            "epoch 44 step 17200 loss 0.8672\n",
            "epoch 44 step 17204 loss 0.8067\n",
            "epoch 44 Train accuracy: 0.7462 loss: 0.7234\n",
            "epoch 44 Test accuracy: 0.5276 loss: 1.5604\n",
            "\n",
            "Starting epoch 45\n",
            "epoch 45 step 17300 loss 0.6985\n",
            "epoch 45 step 17400 loss 0.6877\n",
            "epoch 45 step 17500 loss 0.8024\n",
            "epoch 45 step 17595 loss 0.7999\n",
            "epoch 45 Train accuracy: 0.7501 loss: 0.7026\n",
            "epoch 45 Test accuracy: 0.5290 loss: 1.5718\n",
            "\n",
            "Starting epoch 46\n",
            "epoch 46 step 17600 loss 0.6564\n",
            "epoch 46 step 17700 loss 0.7211\n",
            "epoch 46 step 17800 loss 0.7550\n",
            "epoch 46 step 17900 loss 0.7706\n",
            "epoch 46 step 17986 loss 0.7796\n",
            "epoch 46 Train accuracy: 0.7571 loss: 0.6893\n",
            "epoch 46 Test accuracy: 0.5299 loss: 1.5975\n",
            "\n",
            "Starting epoch 47\n",
            "epoch 47 step 18000 loss 0.6397\n",
            "epoch 47 step 18100 loss 0.6934\n",
            "epoch 47 step 18200 loss 0.5973\n",
            "epoch 47 step 18300 loss 0.8392\n",
            "epoch 47 step 18377 loss 0.8482\n",
            "epoch 47 Train accuracy: 0.7571 loss: 0.6840\n",
            "epoch 47 Test accuracy: 0.5238 loss: 1.6153\n",
            "\n",
            "Starting epoch 48\n",
            "epoch 48 step 18400 loss 0.7319\n",
            "epoch 48 step 18500 loss 0.7880\n",
            "epoch 48 step 18600 loss 0.8141\n",
            "epoch 48 step 18700 loss 0.5655\n",
            "epoch 48 step 18768 loss 0.7610\n",
            "epoch 48 Train accuracy: 0.7626 loss: 0.6731\n",
            "epoch 48 Test accuracy: 0.5262 loss: 1.6301\n",
            "\n",
            "Starting epoch 49\n",
            "epoch 49 step 18800 loss 0.8033\n",
            "epoch 49 step 18900 loss 0.6468\n",
            "epoch 49 step 19000 loss 0.7134\n",
            "epoch 49 step 19100 loss 0.7661\n",
            "epoch 49 step 19159 loss 0.7313\n",
            "epoch 49 Train accuracy: 0.7692 loss: 0.6549\n",
            "epoch 49 Test accuracy: 0.5272 loss: 1.6513\n",
            "\n",
            "Starting epoch 50\n",
            "epoch 50 step 19200 loss 0.5489\n",
            "epoch 50 step 19300 loss 0.6951\n",
            "epoch 50 step 19400 loss 0.6400\n",
            "epoch 50 step 19500 loss 0.8838\n",
            "epoch 50 step 19550 loss 0.5823\n",
            "epoch 50 Train accuracy: 0.7716 loss: 0.6469\n",
            "epoch 50 Test accuracy: 0.5229 loss: 1.6573\n",
            "\n",
            "Starting epoch 51\n",
            "epoch 51 step 19600 loss 0.7671\n",
            "epoch 51 step 19700 loss 0.6063\n",
            "epoch 51 step 19800 loss 0.6992\n",
            "epoch 51 step 19900 loss 0.6409\n",
            "epoch 51 step 19941 loss 0.6520\n",
            "epoch 51 Train accuracy: 0.7743 loss: 0.6403\n",
            "epoch 51 Test accuracy: 0.5146 loss: 1.7010\n",
            "\n",
            "Starting epoch 52\n",
            "epoch 52 step 20000 loss 0.7330\n",
            "epoch 52 step 20100 loss 0.6318\n",
            "epoch 52 step 20200 loss 0.6552\n",
            "epoch 52 step 20300 loss 0.7436\n",
            "epoch 52 step 20332 loss 0.5373\n",
            "epoch 52 Train accuracy: 0.7777 loss: 0.6311\n",
            "epoch 52 Test accuracy: 0.5196 loss: 1.7244\n",
            "\n",
            "Starting epoch 53\n",
            "epoch 53 step 20400 loss 0.5796\n",
            "epoch 53 step 20500 loss 0.5901\n",
            "epoch 53 step 20600 loss 0.6799\n",
            "epoch 53 step 20700 loss 0.6116\n",
            "epoch 53 step 20723 loss 0.5633\n",
            "epoch 53 Train accuracy: 0.7867 loss: 0.6064\n",
            "epoch 53 Test accuracy: 0.5237 loss: 1.7050\n",
            "\n",
            "Starting epoch 54\n",
            "epoch 54 step 20800 loss 0.6232\n",
            "epoch 54 step 20900 loss 0.5536\n",
            "epoch 54 step 21000 loss 0.6065\n",
            "epoch 54 step 21100 loss 0.6883\n",
            "epoch 54 step 21114 loss 0.6833\n",
            "epoch 54 Train accuracy: 0.7946 loss: 0.5896\n",
            "epoch 54 Test accuracy: 0.5255 loss: 1.7221\n",
            "\n",
            "Starting epoch 55\n",
            "epoch 55 step 21200 loss 0.7265\n",
            "epoch 55 step 21300 loss 0.7040\n",
            "epoch 55 step 21400 loss 0.6334\n",
            "epoch 55 step 21500 loss 0.7359\n",
            "epoch 55 step 21505 loss 0.5501\n",
            "epoch 55 Train accuracy: 0.7954 loss: 0.5845\n",
            "epoch 55 Test accuracy: 0.5173 loss: 1.7766\n",
            "\n",
            "Starting epoch 56\n",
            "epoch 56 step 21600 loss 0.5504\n",
            "epoch 56 step 21700 loss 0.5709\n",
            "epoch 56 step 21800 loss 0.5781\n",
            "epoch 56 step 21896 loss 0.6785\n",
            "epoch 56 Train accuracy: 0.7964 loss: 0.5798\n",
            "epoch 56 Test accuracy: 0.5226 loss: 1.7769\n",
            "\n",
            "Starting epoch 57\n",
            "epoch 57 step 21900 loss 0.6852\n",
            "epoch 57 step 22000 loss 0.7113\n",
            "epoch 57 step 22100 loss 0.4151\n",
            "epoch 57 step 22200 loss 0.6285\n",
            "epoch 57 step 22287 loss 0.4890\n",
            "epoch 57 Train accuracy: 0.7983 loss: 0.5730\n",
            "epoch 57 Test accuracy: 0.5118 loss: 1.8241\n",
            "\n",
            "Starting epoch 58\n",
            "epoch 58 step 22300 loss 0.5700\n",
            "epoch 58 step 22400 loss 0.6109\n",
            "epoch 58 step 22500 loss 0.6885\n",
            "epoch 58 step 22600 loss 0.6163\n",
            "epoch 58 step 22678 loss 0.6057\n",
            "epoch 58 Train accuracy: 0.8070 loss: 0.5519\n",
            "epoch 58 Test accuracy: 0.5167 loss: 1.8415\n",
            "\n",
            "Starting epoch 59\n",
            "epoch 59 step 22700 loss 0.6425\n",
            "epoch 59 step 22800 loss 0.6120\n",
            "epoch 59 step 22900 loss 0.6389\n",
            "epoch 59 step 23000 loss 0.7731\n",
            "epoch 59 step 23069 loss 0.6476\n",
            "epoch 59 Train accuracy: 0.8064 loss: 0.5520\n",
            "epoch 59 Test accuracy: 0.5168 loss: 1.8326\n",
            "\n",
            "Starting epoch 60\n",
            "epoch 60 step 23100 loss 0.6032\n",
            "epoch 60 step 23200 loss 0.4479\n",
            "epoch 60 step 23300 loss 0.5228\n",
            "epoch 60 step 23400 loss 0.6092\n",
            "epoch 60 step 23460 loss 0.6401\n",
            "epoch 60 Train accuracy: 0.8072 loss: 0.5436\n",
            "epoch 60 Test accuracy: 0.5163 loss: 1.8840\n",
            "\n",
            "Starting epoch 61\n",
            "epoch 61 step 23500 loss 0.7354\n",
            "epoch 61 step 23600 loss 0.5444\n",
            "epoch 61 step 23700 loss 0.5966\n",
            "epoch 61 step 23800 loss 0.7133\n",
            "epoch 61 step 23851 loss 0.6280\n",
            "epoch 61 Train accuracy: 0.8175 loss: 0.5207\n",
            "epoch 61 Test accuracy: 0.5169 loss: 1.8894\n",
            "\n",
            "Starting epoch 62\n",
            "epoch 62 step 23900 loss 0.4476\n",
            "epoch 62 step 24000 loss 0.6069\n",
            "epoch 62 step 24100 loss 0.6605\n",
            "epoch 62 step 24200 loss 0.5674\n",
            "epoch 62 step 24242 loss 0.5045\n",
            "epoch 62 Train accuracy: 0.8178 loss: 0.5177\n",
            "epoch 62 Test accuracy: 0.5157 loss: 1.9235\n",
            "\n",
            "Starting epoch 63\n",
            "epoch 63 step 24300 loss 0.5461\n",
            "epoch 63 step 24400 loss 0.6405\n",
            "epoch 63 step 24500 loss 0.5312\n",
            "epoch 63 step 24600 loss 0.5789\n",
            "epoch 63 step 24633 loss 0.3500\n",
            "epoch 63 Train accuracy: 0.8241 loss: 0.5040\n",
            "epoch 63 Test accuracy: 0.5119 loss: 1.9473\n",
            "\n",
            "Starting epoch 64\n",
            "epoch 64 step 24700 loss 0.5095\n",
            "epoch 64 step 24800 loss 0.3626\n",
            "epoch 64 step 24900 loss 0.6053\n",
            "epoch 64 step 25000 loss 0.6403\n",
            "epoch 64 step 25024 loss 0.6037\n",
            "epoch 64 Train accuracy: 0.8279 loss: 0.4885\n",
            "epoch 64 Test accuracy: 0.5137 loss: 1.9628\n",
            "\n",
            "Starting epoch 65\n",
            "epoch 65 step 25100 loss 0.4798\n",
            "epoch 65 step 25200 loss 0.5133\n",
            "epoch 65 step 25300 loss 0.4724\n",
            "epoch 65 step 25400 loss 0.6469\n",
            "epoch 65 step 25415 loss 0.4482\n",
            "epoch 65 Train accuracy: 0.8304 loss: 0.4832\n",
            "epoch 65 Test accuracy: 0.5129 loss: 1.9749\n",
            "\n",
            "Starting epoch 66\n",
            "epoch 66 step 25500 loss 0.3428\n",
            "epoch 66 step 25600 loss 0.6965\n",
            "epoch 66 step 25700 loss 0.5243\n",
            "epoch 66 step 25800 loss 0.5901\n",
            "epoch 66 step 25806 loss 0.5710\n",
            "epoch 66 Train accuracy: 0.8286 loss: 0.4854\n",
            "epoch 66 Test accuracy: 0.5095 loss: 2.0159\n",
            "\n",
            "Starting epoch 67\n",
            "epoch 67 step 25900 loss 0.5542\n",
            "epoch 67 step 26000 loss 0.4599\n",
            "epoch 67 step 26100 loss 0.4143\n",
            "epoch 67 step 26197 loss 0.3852\n",
            "epoch 67 Train accuracy: 0.8324 loss: 0.4784\n",
            "epoch 67 Test accuracy: 0.5124 loss: 2.0208\n",
            "\n",
            "Starting epoch 68\n",
            "epoch 68 step 26200 loss 0.5641\n",
            "epoch 68 step 26300 loss 0.5152\n",
            "epoch 68 step 26400 loss 0.5158\n",
            "epoch 68 step 26500 loss 0.6424\n",
            "epoch 68 step 26588 loss 0.4890\n",
            "epoch 68 Train accuracy: 0.8382 loss: 0.4612\n",
            "epoch 68 Test accuracy: 0.5216 loss: 2.0258\n",
            "\n",
            "Starting epoch 69\n",
            "epoch 69 step 26600 loss 0.4435\n",
            "epoch 69 step 26700 loss 0.4299\n",
            "epoch 69 step 26800 loss 0.3974\n",
            "epoch 69 step 26900 loss 0.5367\n",
            "epoch 69 step 26979 loss 0.5658\n",
            "epoch 69 Train accuracy: 0.8439 loss: 0.4434\n",
            "epoch 69 Test accuracy: 0.5130 loss: 2.0617\n",
            "\n",
            "Starting epoch 70\n",
            "epoch 70 step 27000 loss 0.5040\n",
            "epoch 70 step 27100 loss 0.4367\n",
            "epoch 70 step 27200 loss 0.3893\n",
            "epoch 70 step 27300 loss 0.5853\n",
            "epoch 70 step 27370 loss 0.5692\n",
            "epoch 70 Train accuracy: 0.8436 loss: 0.4464\n",
            "epoch 70 Test accuracy: 0.5106 loss: 2.0930\n",
            "\n",
            "Starting epoch 71\n",
            "epoch 71 step 27400 loss 0.6448\n",
            "epoch 71 step 27500 loss 0.4684\n",
            "epoch 71 step 27600 loss 0.4869\n",
            "epoch 71 step 27700 loss 0.5342\n",
            "epoch 71 step 27761 loss 0.5043\n",
            "epoch 71 Train accuracy: 0.8503 loss: 0.4270\n",
            "epoch 71 Test accuracy: 0.5101 loss: 2.1253\n",
            "\n",
            "Starting epoch 72\n",
            "epoch 72 step 27800 loss 0.5191\n",
            "epoch 72 step 27900 loss 0.4508\n",
            "epoch 72 step 28000 loss 0.5373\n",
            "epoch 72 step 28100 loss 0.4977\n",
            "epoch 72 step 28152 loss 0.4822\n",
            "epoch 72 Train accuracy: 0.8517 loss: 0.4260\n",
            "epoch 72 Test accuracy: 0.5081 loss: 2.1496\n",
            "\n",
            "Starting epoch 73\n",
            "epoch 73 step 28200 loss 0.4927\n",
            "epoch 73 step 28300 loss 0.3752\n",
            "epoch 73 step 28400 loss 0.5124\n",
            "epoch 73 step 28500 loss 0.5371\n",
            "epoch 73 step 28543 loss 0.5148\n",
            "epoch 73 Train accuracy: 0.8496 loss: 0.4269\n",
            "epoch 73 Test accuracy: 0.5094 loss: 2.1669\n",
            "\n",
            "Starting epoch 74\n",
            "epoch 74 step 28600 loss 0.4647\n",
            "epoch 74 step 28700 loss 0.5728\n",
            "epoch 74 step 28800 loss 0.3890\n",
            "epoch 74 step 28900 loss 0.4850\n",
            "epoch 74 step 28934 loss 0.4453\n",
            "epoch 74 Train accuracy: 0.8582 loss: 0.4090\n",
            "epoch 74 Test accuracy: 0.5113 loss: 2.1722\n",
            "\n",
            "Starting epoch 75\n",
            "epoch 75 step 29000 loss 0.3780\n",
            "epoch 75 step 29100 loss 0.4991\n",
            "epoch 75 step 29200 loss 0.4815\n",
            "epoch 75 step 29300 loss 0.4311\n",
            "epoch 75 step 29325 loss 0.3971\n",
            "epoch 75 Train accuracy: 0.8604 loss: 0.4048\n",
            "epoch 75 Test accuracy: 0.5020 loss: 2.2346\n",
            "\n",
            "Starting epoch 76\n",
            "epoch 76 step 29400 loss 0.5956\n",
            "epoch 76 step 29500 loss 0.4550\n",
            "epoch 76 step 29600 loss 0.4318\n",
            "epoch 76 step 29700 loss 0.6255\n",
            "epoch 76 step 29716 loss 0.4387\n",
            "epoch 76 Train accuracy: 0.8580 loss: 0.4043\n",
            "epoch 76 Test accuracy: 0.5052 loss: 2.2687\n",
            "\n",
            "Starting epoch 77\n",
            "epoch 77 step 29800 loss 0.4849\n",
            "epoch 77 step 29900 loss 0.5547\n",
            "epoch 77 step 30000 loss 0.4151\n",
            "epoch 77 step 30100 loss 0.4660\n",
            "epoch 77 step 30107 loss 0.4734\n",
            "epoch 77 Train accuracy: 0.8604 loss: 0.4008\n",
            "epoch 77 Test accuracy: 0.5038 loss: 2.2608\n",
            "\n",
            "Starting epoch 78\n",
            "epoch 78 step 30200 loss 0.4800\n",
            "epoch 78 step 30300 loss 0.4157\n",
            "epoch 78 step 30400 loss 0.4300\n",
            "epoch 78 step 30498 loss 0.5733\n",
            "epoch 78 Train accuracy: 0.8616 loss: 0.3960\n",
            "epoch 78 Test accuracy: 0.5066 loss: 2.2917\n",
            "\n",
            "Starting epoch 79\n",
            "epoch 79 step 30500 loss 0.4067\n",
            "epoch 79 step 30600 loss 0.3470\n",
            "epoch 79 step 30700 loss 0.5022\n",
            "epoch 79 step 30800 loss 0.4618\n",
            "epoch 79 step 30889 loss 0.5134\n",
            "epoch 79 Train accuracy: 0.8687 loss: 0.3782\n",
            "epoch 79 Test accuracy: 0.5054 loss: 2.3018\n",
            "\n",
            "Starting epoch 80\n",
            "epoch 80 step 30900 loss 0.4163\n",
            "epoch 80 step 31000 loss 0.3930\n",
            "epoch 80 step 31100 loss 0.3537\n",
            "epoch 80 step 31200 loss 0.5165\n",
            "epoch 80 step 31280 loss 0.3293\n",
            "epoch 80 Train accuracy: 0.8708 loss: 0.3708\n",
            "epoch 80 Test accuracy: 0.5085 loss: 2.3296\n",
            "\n",
            "Starting epoch 81\n",
            "epoch 81 step 31300 loss 0.3370\n",
            "epoch 81 step 31400 loss 0.4629\n",
            "epoch 81 step 31500 loss 0.5017\n",
            "epoch 81 step 31600 loss 0.3998\n",
            "epoch 81 step 31671 loss 0.4892\n",
            "epoch 81 Train accuracy: 0.8752 loss: 0.3600\n",
            "epoch 81 Test accuracy: 0.4989 loss: 2.3658\n",
            "\n",
            "Starting epoch 82\n",
            "epoch 82 step 31700 loss 0.3904\n",
            "epoch 82 step 31800 loss 0.3507\n",
            "epoch 82 step 31900 loss 0.4323\n",
            "epoch 82 step 32000 loss 0.5812\n",
            "epoch 82 step 32062 loss 0.3552\n",
            "epoch 82 Train accuracy: 0.8743 loss: 0.3610\n",
            "epoch 82 Test accuracy: 0.5025 loss: 2.3781\n",
            "\n",
            "Starting epoch 83\n",
            "epoch 83 step 32100 loss 0.3486\n",
            "epoch 83 step 32200 loss 0.5420\n",
            "epoch 83 step 32300 loss 0.3656\n",
            "epoch 83 step 32400 loss 0.4923\n",
            "epoch 83 step 32453 loss 0.3682\n",
            "epoch 83 Train accuracy: 0.8776 loss: 0.3553\n",
            "epoch 83 Test accuracy: 0.5028 loss: 2.3799\n",
            "\n",
            "Starting epoch 84\n",
            "epoch 84 step 32500 loss 0.3772\n",
            "epoch 84 step 32600 loss 0.3542\n",
            "epoch 84 step 32700 loss 0.4360\n",
            "epoch 84 step 32800 loss 0.3813\n",
            "epoch 84 step 32844 loss 0.3146\n",
            "epoch 84 Train accuracy: 0.8812 loss: 0.3477\n",
            "epoch 84 Test accuracy: 0.4985 loss: 2.4253\n",
            "\n",
            "Starting epoch 85\n",
            "epoch 85 step 32900 loss 0.2304\n",
            "epoch 85 step 33000 loss 0.4202\n",
            "epoch 85 step 33100 loss 0.5029\n",
            "epoch 85 step 33200 loss 0.5715\n",
            "epoch 85 step 33235 loss 0.3913\n",
            "epoch 85 Train accuracy: 0.8827 loss: 0.3416\n",
            "epoch 85 Test accuracy: 0.5031 loss: 2.4173\n",
            "\n",
            "Starting epoch 86\n",
            "epoch 86 step 33300 loss 0.3127\n",
            "epoch 86 step 33400 loss 0.2165\n",
            "epoch 86 step 33500 loss 0.3325\n",
            "epoch 86 step 33600 loss 0.3390\n",
            "epoch 86 step 33626 loss 0.4093\n",
            "epoch 86 Train accuracy: 0.8842 loss: 0.3372\n",
            "epoch 86 Test accuracy: 0.4987 loss: 2.4962\n",
            "\n",
            "Starting epoch 87\n",
            "epoch 87 step 33700 loss 0.3346\n",
            "epoch 87 step 33800 loss 0.3029\n",
            "epoch 87 step 33900 loss 0.4522\n",
            "epoch 87 step 34000 loss 0.4595\n",
            "epoch 87 step 34017 loss 0.3699\n",
            "epoch 87 Train accuracy: 0.8898 loss: 0.3206\n",
            "epoch 87 Test accuracy: 0.4987 loss: 2.5153\n",
            "\n",
            "Starting epoch 88\n",
            "epoch 88 step 34100 loss 0.3532\n",
            "epoch 88 step 34200 loss 0.3467\n",
            "epoch 88 step 34300 loss 0.2822\n",
            "epoch 88 step 34400 loss 0.2909\n",
            "epoch 88 step 34408 loss 0.4646\n",
            "epoch 88 Train accuracy: 0.8870 loss: 0.3275\n",
            "epoch 88 Test accuracy: 0.5015 loss: 2.5058\n",
            "\n",
            "Starting epoch 89\n",
            "epoch 89 step 34500 loss 0.3186\n",
            "epoch 89 step 34600 loss 0.3613\n",
            "epoch 89 step 34700 loss 0.4640\n",
            "epoch 89 step 34799 loss 0.3693\n",
            "epoch 89 Train accuracy: 0.8925 loss: 0.3116\n",
            "epoch 89 Test accuracy: 0.5030 loss: 2.4967\n",
            "\n",
            "Starting epoch 90\n",
            "epoch 90 step 34800 loss 0.3465\n",
            "epoch 90 step 34900 loss 0.3412\n",
            "epoch 90 step 35000 loss 0.4225\n",
            "epoch 90 step 35100 loss 0.3502\n",
            "epoch 90 step 35190 loss 0.2544\n",
            "epoch 90 Train accuracy: 0.8889 loss: 0.3245\n",
            "epoch 90 Test accuracy: 0.4972 loss: 2.5776\n",
            "\n",
            "Starting epoch 91\n",
            "epoch 91 step 35200 loss 0.3131\n",
            "epoch 91 step 35300 loss 0.3694\n",
            "epoch 91 step 35400 loss 0.3184\n",
            "epoch 91 step 35500 loss 0.4371\n",
            "epoch 91 step 35581 loss 0.4625\n",
            "epoch 91 Train accuracy: 0.8982 loss: 0.2953\n",
            "epoch 91 Test accuracy: 0.5001 loss: 2.5749\n",
            "\n",
            "Starting epoch 92\n",
            "epoch 92 step 35600 loss 0.3323\n",
            "epoch 92 step 35700 loss 0.3187\n",
            "epoch 92 step 35800 loss 0.4811\n",
            "epoch 92 step 35900 loss 0.4505\n",
            "epoch 92 step 35972 loss 0.3496\n",
            "epoch 92 Train accuracy: 0.8924 loss: 0.3168\n",
            "epoch 92 Test accuracy: 0.5004 loss: 2.6313\n",
            "\n",
            "Starting epoch 93\n",
            "epoch 93 step 36000 loss 0.4204\n",
            "epoch 93 step 36100 loss 0.3724\n",
            "epoch 93 step 36200 loss 0.2513\n",
            "epoch 93 step 36300 loss 0.2692\n",
            "epoch 93 step 36363 loss 0.2832\n",
            "epoch 93 Train accuracy: 0.8983 loss: 0.2948\n",
            "epoch 93 Test accuracy: 0.4962 loss: 2.6231\n",
            "\n",
            "Starting epoch 94\n",
            "epoch 94 step 36400 loss 0.2531\n",
            "epoch 94 step 36500 loss 0.2875\n",
            "epoch 94 step 36600 loss 0.3082\n",
            "epoch 94 step 36700 loss 0.2815\n",
            "epoch 94 step 36754 loss 0.3040\n",
            "epoch 94 Train accuracy: 0.8946 loss: 0.3019\n",
            "epoch 94 Test accuracy: 0.4980 loss: 2.6794\n",
            "\n",
            "Starting epoch 95\n",
            "epoch 95 step 36800 loss 0.3001\n",
            "epoch 95 step 36900 loss 0.2994\n",
            "epoch 95 step 37000 loss 0.3179\n",
            "epoch 95 step 37100 loss 0.3515\n",
            "epoch 95 step 37145 loss 0.4724\n",
            "epoch 95 Train accuracy: 0.8975 loss: 0.2967\n",
            "epoch 95 Test accuracy: 0.4980 loss: 2.6538\n",
            "\n",
            "Starting epoch 96\n",
            "epoch 96 step 37200 loss 0.3412\n",
            "epoch 96 step 37300 loss 0.2960\n",
            "epoch 96 step 37400 loss 0.3276\n",
            "epoch 96 step 37500 loss 0.3306\n",
            "epoch 96 step 37536 loss 0.4412\n",
            "epoch 96 Train accuracy: 0.8974 loss: 0.2945\n",
            "epoch 96 Test accuracy: 0.4935 loss: 2.6997\n",
            "\n",
            "Starting epoch 97\n",
            "epoch 97 step 37600 loss 0.2474\n",
            "epoch 97 step 37700 loss 0.3235\n",
            "epoch 97 step 37800 loss 0.2960\n",
            "epoch 97 step 37900 loss 0.2252\n",
            "epoch 97 step 37927 loss 0.3371\n",
            "epoch 97 Train accuracy: 0.9011 loss: 0.2899\n",
            "epoch 97 Test accuracy: 0.4977 loss: 2.7078\n",
            "\n",
            "Starting epoch 98\n",
            "epoch 98 step 38000 loss 0.2294\n",
            "epoch 98 step 38100 loss 0.4374\n",
            "epoch 98 step 38200 loss 0.2881\n",
            "epoch 98 step 38300 loss 0.3518\n",
            "epoch 98 step 38318 loss 0.3022\n",
            "epoch 98 Train accuracy: 0.9049 loss: 0.2788\n",
            "epoch 98 Test accuracy: 0.5012 loss: 2.7166\n",
            "\n",
            "Starting epoch 99\n",
            "epoch 99 step 38400 loss 0.3149\n",
            "epoch 99 step 38500 loss 0.3486\n",
            "epoch 99 step 38600 loss 0.2510\n",
            "epoch 99 step 38700 loss 0.3398\n",
            "epoch 99 step 38709 loss 0.3127\n",
            "epoch 99 Train accuracy: 0.9101 loss: 0.2665\n",
            "epoch 99 Test accuracy: 0.4984 loss: 2.7224\n",
            "\n",
            "Starting epoch 100\n",
            "epoch 100 step 38800 loss 0.2365\n",
            "epoch 100 step 38900 loss 0.2227\n",
            "epoch 100 step 39000 loss 0.3237\n",
            "epoch 100 step 39100 loss 0.3725\n",
            "epoch 100 Train accuracy: 0.9102 loss: 0.2673\n",
            "epoch 100 Test accuracy: 0.4980 loss: 2.7753\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htRfIj6Tn5AE"
      },
      "source": [
        "Starting epoch 1\n",
        "epoch 1 Train accuracy: 0.2149 loss: 2.1175\n",
        "epoch 1 Test accuracy: 0.2099 loss: 2.1230\n",
        "\n",
        "Starting epoch 2\n",
        "epoch 2 Train accuracy: 0.2630 loss: 2.0121\n",
        "epoch 2 Test accuracy: 0.2568 loss: 2.0234\n",
        "\n",
        "Starting epoch 3\n",
        "epoch 3 Train accuracy: 0.3049 loss: 1.9212\n",
        "epoch 3 Test accuracy: 0.2926 loss: 1.9452\n",
        "\n",
        "Starting epoch 4\n",
        "epoch 4 Train accuracy: 0.3238 loss: 1.8783\n",
        "epoch 4 Test accuracy: 0.3044 loss: 1.9204\n",
        "\n",
        "Starting epoch 5\n",
        "epoch 5 Train accuracy: 0.3507 loss: 1.8155\n",
        "epoch 5 Test accuracy: 0.3311 loss: 1.8677\n",
        "\n",
        "Starting epoch 6\n",
        "epoch 6 Train accuracy: 0.3613 loss: 1.7780\n",
        "epoch 6 Test accuracy: 0.3315 loss: 1.8519\n",
        "\n",
        "Starting epoch 7\n",
        "epoch 7 Train accuracy: 0.3804 loss: 1.7315\n",
        "epoch 7 Test accuracy: 0.3404 loss: 1.8337\n",
        "\n",
        "Starting epoch 8\n",
        "epoch 8 Train accuracy: 0.3959 loss: 1.6926\n",
        "epoch 8 Test accuracy: 0.3443 loss: 1.8230\n",
        "\n",
        "Starting epoch 9\n",
        "epoch 9 Train accuracy: 0.4155 loss: 1.6319\n",
        "epoch 9 Test accuracy: 0.3509 loss: 1.8061\n",
        "\n",
        "Starting epoch 10\n",
        "epoch 10 Train accuracy: 0.4371 loss: 1.5848\n",
        "epoch 10 Test accuracy: 0.3573 loss: 1.7931\n",
        "\n",
        "Starting epoch 11\n",
        "epoch 11 Train accuracy: 0.4526 loss: 1.5444\n",
        "epoch 11 Test accuracy: 0.3527 loss: 1.8109\n",
        "\n",
        "Starting epoch 12\n",
        "epoch 12 Train accuracy: 0.4790 loss: 1.4834\n",
        "epoch 12 Test accuracy: 0.3623 loss: 1.7963\n",
        "\n",
        "Starting epoch 13\n",
        "epoch 13 Train accuracy: 0.4951 loss: 1.4388\n",
        "epoch 13 Test accuracy: 0.3534 loss: 1.8314\n",
        "\n",
        "Starting epoch 14\n",
        "epoch 14 Train accuracy: 0.5201 loss: 1.3662\n",
        "epoch 14 Test accuracy: 0.3575 loss: 1.8386\n",
        "\n",
        "Starting epoch 15\n",
        "epoch 15 Train accuracy: 0.5374 loss: 1.3202\n",
        "epoch 15 Test accuracy: 0.3539 loss: 1.8746\n",
        "\n",
        "Starting epoch 16\n",
        "epoch 16 Train accuracy: 0.5430 loss: 1.2864\n",
        "epoch 16 Test accuracy: 0.3480 loss: 1.9401\n",
        "\n",
        "Starting epoch 17\n",
        "epoch 17 Train accuracy: 0.5807 loss: 1.2018\n",
        "epoch 17 Test accuracy: 0.3478 loss: 1.9427\n",
        "\n",
        "Starting epoch 18\n",
        "epoch 18 Train accuracy: 0.6062 loss: 1.1391\n",
        "epoch 18 Test accuracy: 0.3426 loss: 1.9859\n",
        "\n",
        "Starting epoch 19\n",
        "epoch 19 Train accuracy: 0.6255 loss: 1.0780\n",
        "epoch 19 Test accuracy: 0.3333 loss: 2.0762"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lDa20QkcQim"
      },
      "source": [
        "# Batch Size Ablation on Smaller Architecture, 12 epochs, CIFAR-10\n",
        "# Fixed model architecture for ablation study\n",
        "# model_args=C(\n",
        "#             dim = 32,                    # dimension of sequence to be encoded\n",
        "#             queries_dim = 10,            # dimension of decoder queries\n",
        "#             logits_dim = 10,            # dimension of final logits\n",
        "#             depth = 2,                   # depth of net\n",
        "#             num_latents = 32,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "#             latent_dim = 64,            # latent dimension\n",
        "#             cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
        "#             latent_heads = 8,            # number of heads for latent self attention, 8\n",
        "#             cross_dim_head = 64,         # number of dimensions per cross attention head\n",
        "#             latent_dim_head = 64,        # number of dimensions per latent self attention head\n",
        "#             weight_tie_layers = False,    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        "#             decoder_ff = False\n",
        "#         ),\n",
        "batch_size = [8, 16, 32, 64, 128]\n",
        "final_test_accuracies = [0.1468, 0.2099, 0.3, 0.3623, 0.3852]\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMHrp8bBEZQ9"
      },
      "source": [
        "epoch = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}